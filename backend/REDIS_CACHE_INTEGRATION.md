# Redis Cache Integration - Complete ‚úÖ

## Overview

Redis cache has been **successfully integrated** into the GHL Workflow Debugger backend with full production-ready features including automatic fallback to in-memory cache when Redis is unavailable.

---

## ‚úÖ Implementation Status

### 1. Redis Client Installation
- **Package:** `ioredis@^5.3.0` - ‚úÖ Installed
- **TypeScript Types:** `@types/ioredis` - ‚úÖ Installed

### 2. Cache Service (`src/lib/cache.ts`)
- ‚úÖ **Dual-mode caching:** Seamlessly switches between Redis and in-memory
- ‚úÖ **Graceful fallback:** Automatically falls back to in-memory if Redis fails
- ‚úÖ **Connection pooling:** Built-in with ioredis
- ‚úÖ **Automatic reconnection:** Configurable retry strategy with exponential backoff
- ‚úÖ **TTL support:** Configurable time-to-live for all cache entries
- ‚úÖ **Key prefixing:** Structured key naming with `CacheKeys` helper

### 3. Features Implemented

#### Core Features
```typescript
// Get cached data
const data = await cache.get<Type>('key');

// Set data with TTL
await cache.set('key', data, 300); // 5 minutes

// Delete key
await cache.del('key');

// Check existence
const exists = await cache.exists('key');

// Wrap function with caching
const result = await cache.wrap('key', async () => {
  return await expensiveOperation();
}, 3600);

// Flush all cache
await cache.flush();

// Get cache statistics
const stats = cache.getStats();
```

#### Key Prefixing Helpers
```typescript
CacheKeys.workflow(locationId, workflowId)     // "workflow:loc123:wf456"
CacheKeys.workflows(locationId)                 // "workflows:loc123"
CacheKeys.analysis(workflowId)                  // "analysis:wf456"
CacheKeys.user(locationId)                      // "user:loc123"
CacheKeys.subscription(locationId)              // "subscription:loc123"
```

#### TTL Constants
```typescript
CacheTTL.SHORT      // 60s (1 minute)
CacheTTL.MEDIUM     // 300s (5 minutes)
CacheTTL.WORKFLOW   // 600s (10 minutes)
CacheTTL.USER       // 900s (15 minutes)
CacheTTL.LONG       // 1800s (30 minutes)
CacheTTL.ANALYSIS   // 3600s (1 hour)
```

### 4. Environment Configuration
```bash
# Production (with Redis)
REDIS_URL=redis://default:password@host:6379

# Development (in-memory fallback)
# Leave REDIS_URL empty or unset
```

### 5. Current Cache Usages

The cache is currently being used in:

**File:** `src/routes/api.ts`
- Workflow list caching
- Individual workflow caching
- Workflow analysis result caching
- Analysis performance optimization

**Cache hit/miss metrics tracked via:**
- `recordCacheOperation()` function
- Prometheus metrics endpoint

### 6. Health Check Integration ‚úÖ

A comprehensive health check has been added to monitor Redis/cache status:

**Endpoint:** `GET /health/detailed`

**Response Example (Redis connected):**
```json
{
  "status": "healthy",
  "service": "ghl-workflow-debugger",
  "version": "1.0.0",
  "timestamp": "2025-01-10T12:00:00.000Z",
  "environment": "production",
  "checks": {
    "database": "healthy",
    "cache": {
      "status": "healthy",
      "type": "redis",
      "connected": true
    },
    "memory": {
      "used": 45,
      "total": 128,
      "unit": "MB"
    },
    "uptime": 3600
  }
}
```

**Response Example (Fallback to in-memory):**
```json
{
  "status": "degraded",
  "checks": {
    "cache": {
      "status": "degraded",
      "type": "in-memory",
      "size": 42,
      "message": "Redis unavailable, using fallback"
    }
  }
}
```

---

## üöÄ Deployment Instructions

### Option 1: Using Redis Cloud (Recommended for Production)
```bash
# Sign up at: https://redis.com/try-free/
# Copy your connection URL

# Add to .env or environment variables:
REDIS_URL=redis://default:your-password@your-host.redis.cloud:16379
```

### Option 2: Using Railway Redis
```bash
# In Railway dashboard:
# 1. Add Redis service to your project
# 2. Railway auto-generates REDIS_URL
# 3. No additional configuration needed
```

### Option 3: Using Upstash Redis (Serverless)
```bash
# Sign up at: https://upstash.com/
# Create Redis database
# Copy connection string

REDIS_URL=redis://default:your-token@your-region.upstash.io:6379
```

### Option 4: Local Development (Docker)
```bash
# Run Redis locally
docker run -d -p 6379:6379 redis:7-alpine

# .env configuration
REDIS_URL=redis://localhost:6379
```

---

## üß™ Testing

### Test Redis Connection
```bash
# Start the backend
npm run dev

# Check health endpoint
curl http://localhost:3000/health/detailed

# Should show cache.type = "redis" if connected
```

### Test Fallback Behavior
```bash
# 1. Start backend with Redis
# 2. Disconnect Redis
# 3. Backend automatically falls back to in-memory
# 4. No errors or downtime!
```

### Test Cache Performance
```bash
# Endpoint with caching
curl http://localhost:3000/api/workflows?locationId=xxx

# First call: cache miss (slow)
# Second call: cache hit (fast)
# Check X-Cache-Status header
```

---

## üìä Monitoring

### Cache Statistics
```bash
# Internal cache stats endpoint
GET /internal/cache-stats

# Response:
{
  "type": "redis",
  "connected": true
}
```

### Prometheus Metrics
```bash
GET /metrics

# Includes cache hit/miss metrics:
cache_operations_total{type="redis",operation="hit",resource="workflows"}
cache_operations_total{type="redis",operation="miss",resource="workflows"}
```

---

## üîß Configuration Options

### Redis Connection Options (src/lib/cache.ts)
```typescript
new Redis(REDIS_URL, {
  maxRetriesPerRequest: 3,
  enableReadyCheck: true,
  retryStrategy: (times: number) => {
    if (times > 3) return null; // Stop retrying
    return Math.min(times * 100, 3000); // Exponential backoff
  }
});
```

### In-Memory Cache Limits
```typescript
class InMemoryCache {
  private maxSize = 1000; // Maximum 1000 items
  // Oldest items automatically evicted (LRU-like)
}
```

---

## üõ°Ô∏è Production Best Practices

### 1. Set Redis URL in Production
```bash
# Required for production deployments
REDIS_URL=redis://default:password@host:6379
```

### 2. Monitor Cache Health
- Use `/health/detailed` endpoint
- Set up alerts for `cache.status !== "healthy"`
- Track cache hit/miss ratios

### 3. Configure TTL Based on Data Type
```typescript
// Fast-changing data
await cache.set(key, data, CacheTTL.SHORT);   // 1 minute

// Analysis results (expensive to compute)
await cache.set(key, analysis, CacheTTL.ANALYSIS); // 1 hour
```

### 4. Graceful Shutdown
The cache connection is automatically closed during graceful shutdown:
```typescript
// Handled in src/index.ts
await cache.close();
```

---

## üêõ Troubleshooting

### Problem: Cache shows "in-memory" even with REDIS_URL set
**Solution:**
1. Check REDIS_URL format: `redis://[user]:[password]@host:port`
2. Verify Redis server is accessible
3. Check firewall/security group rules
4. Review logs: `journalctl -u your-service -f`

### Problem: Connection keeps failing
**Solution:**
1. Verify credentials are correct
2. Check Redis server health
3. Increase retry limits in `cache.ts` if needed
4. Use in-memory fallback temporarily

### Problem: High memory usage with in-memory cache
**Solution:**
1. Increase `maxSize` limit in `InMemoryCache` class
2. Reduce TTL values to expire items faster
3. Deploy Redis for production use

---

## ‚úÖ Verification Checklist

- [x] `ioredis` package installed
- [x] `@types/ioredis` types installed
- [x] Cache service implements `CacheService` interface
- [x] Graceful fallback to in-memory cache
- [x] Automatic reconnection with retry logic
- [x] TTL support for all cache operations
- [x] Key prefixing structure defined
- [x] Existing cache usages updated
- [x] Health check endpoint includes cache status
- [x] Environment variable documented in `.env.example`
- [x] TypeScript compilation succeeds
- [x] Graceful shutdown closes Redis connection

---

## üìà Next Steps (Optional Enhancements)

1. **Cache Warming:** Pre-populate cache on startup
2. **Cache Invalidation:** Add webhook for real-time invalidation
3. **Cache Metrics Dashboard:** Visualize hit/miss rates
4. **Multi-Region Redis:** For global deployments
5. **Redis Cluster:** For high-availability scenarios

---

## üìö References

- [ioredis Documentation](https://github.com/redis/ioredis)
- [Redis Best Practices](https://redis.io/docs/manual/patterns/)
- [Cache Invalidation Strategies](https://docs.redis.com/latest/rs/databases/active-active/)

---

**Status:** ‚úÖ **COMPLETE - PRODUCTION READY**

The Redis cache integration is fully implemented, tested, and ready for production deployment with automatic fallback to in-memory cache ensuring zero downtime.
